{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewNg3416/-/blob/master/MWN_240715.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "Ju_qe_szUG_W",
        "outputId": "003a388f-f0db-40d1-911d-c21589f93a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unet:\n",
            "cpu\n",
            "cpu\n",
            "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to ./data/VOCtrainval_11-May-2012.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1999639040/1999639040 [01:11<00:00, 27907057.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-19f34f448da5>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mepoch_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "# 240714\n",
        "\n",
        "\n",
        "from email.mime import image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import VOCSegmentation\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        def conv_block(in_channels, out_channels):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.encoder1 = conv_block(in_channels, 64)\n",
        "        self.encoder2 = conv_block(64, 128)\n",
        "        self.encoder3 = conv_block(128, 256)\n",
        "        self.encoder4 = conv_block(256, 512)\n",
        "        self.bottleneck = conv_block(512, 1024)\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.decoder4 = conv_block(1024, 512)\n",
        "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.decoder3 = conv_block(512, 256)\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.decoder2 = conv_block(256, 128)\n",
        "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.decoder1 = conv_block(128, 64)\n",
        "\n",
        "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(F.max_pool2d(enc1, kernel_size=2, stride=2))\n",
        "        enc3 = self.encoder3(F.max_pool2d(enc2, kernel_size=2, stride=2))\n",
        "        enc4 = self.encoder4(F.max_pool2d(enc3, kernel_size=2, stride=2))\n",
        "        bottleneck = self.bottleneck(F.max_pool2d(enc4, kernel_size=2, stride=2))\n",
        "\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
        "        dec4 = self.decoder4(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "\n",
        "        return self.final(dec1)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"unet:\")\n",
        "    model=UNet(in_channels=3,\n",
        "               out_channels=1)\n",
        "\n",
        "\n",
        "    print(next(model.parameters()).device)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    print(next(model.parameters()).device)\n",
        "\n",
        "    # 数据预处理\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize((128,128)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # 加载Pascal VOC数据集\n",
        "    train_dataset=VOCSegmentation(\n",
        "        root='./data',\n",
        "        year='2012',\n",
        "        image_set='train',\n",
        "        download=True,\n",
        "        transform=transform,\n",
        "        target_transform=transform\n",
        "    )\n",
        "    train_loader=DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=16,\n",
        "        shuffle=True)\n",
        "\n",
        "    criterion=nn.BCEWithLogitsLoss()\n",
        "    optimizer=optim.Adam(model.parameters(),\n",
        "                         lr=.001)\n",
        "    # 训练循环\n",
        "    num_epochs=10\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss=0\n",
        "        for images,masks in train_loader:\n",
        "            images=images.to(device)\n",
        "            masks=masks.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs=model(images)\n",
        "            loss=criterion(outputs,masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss+=loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, \\\n",
        "              Loss: {epoch_loss/len(train_loader)}\")\n",
        "\n",
        "\n",
        "\n",
        "    # print(model)\n",
        "\n",
        "    # 模型评估\n",
        "    model.eval()\n",
        "    i=0\n",
        "    with torch.no_grad():\n",
        "        for images,masks in train_loader:\n",
        "            images=images.to(device)\n",
        "            masks=masks.to(device)\n",
        "            outputs=model(images)\n",
        "            #将结果保存为图片\n",
        "            save_image(outputs,\n",
        "                     'output{i}.png')\n",
        "            i+=1\n",
        "            if(i>10):\n",
        "                break\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"unet----\")\n",
        "print(\"----\")\n",
        "import torch.nn as nn\n",
        "class Unet2(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels) -> None:\n",
        "      super(Unet2,self).__init__()\n",
        "\n",
        "      self.prt=\"prt\"\n",
        "      print(\"Unet init\")\n",
        "\n",
        "unet2 = Unet2(2,3)\n",
        "print(unet2.parameters)\n",
        "a = torch.tensor(2)\n",
        "b = torch.tensor(3)\n",
        "c = a+b\n",
        "import pdb\n",
        "# pdb.set_trace()\n",
        "print(c)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TKz39AhrpEx",
        "outputId": "10b8bfdf-bb68-437b-aa7b-b7e4f351f7ae"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unet----\n",
            "----\n",
            "Unet init\n",
            "<bound method Module.parameters of Unet2()>\n",
            "tensor(5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot_curve(data):\n",
        "  fig=plt.figure()\n",
        "  plt.plot(range(len(data)),\n",
        "           data,\n",
        "           color='blue')\n",
        "  plt.legend(['value'],\n",
        "      loc=\"upper right\")\n",
        "  plt.xlabel('step')\n",
        "  plt.ylabel('value')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_image(img,\n",
        "    label,\n",
        "    name):\n",
        "  fig=plt.figure()\n",
        "  for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.tight_layout()\n",
        "    plt.imshow(img[i]]0]*0.3081+0.1307,cmap='gray',interpolation='none')\n",
        "    plt.title(\"{}:{}\".format(name,label))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  def one_hot(label,depth=10):\n",
        "    out=torch.zeros(label.size(0),depth)\n",
        "    idx=torch.LongTensor(label).view(-1,1)\n",
        "    out.scatter_(dim=1,\n",
        "          index=idx,\n",
        "          value=1)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MXvQzHfwknHo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN0Vb7KJcriFvO4hXIiojMn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}